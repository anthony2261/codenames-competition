{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitcodenamesenvcondae669634ed0994149bbbb1622e4072770",
   "display_name": "Python 3.7.9 64-bit ('codenames_env': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Imports & functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy # after installing, be sure to run 'python -m spacy download en_core_web_lg'\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_matrix(clue_list):\n",
    "    \"\"\"\n",
    "    Takes in a list of words (clues or boardwords) and returns a vector-representation-matrix  of dim {n_words, n_features}\n",
    "    \"\"\"\n",
    "    vector_array = [doc.vector for doc in nlp.pipe(clue_list)]\n",
    "    matrix = np.array(vector_array)\n",
    "    return matrix"
   ]
  },
  {
   "source": [
    "## How ``cosine_distances`` works:\n",
    "Each row corresponds to a word in the X input and each column corresponds to a word in the Y input."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.1339746]]\n"
     ]
    }
   ],
   "source": [
    "vec1 = np.array([[1,1,0,1,1]])\n",
    "vec2 = np.array([[0,1,0,1,1]])\n",
    "print(cosine_distances(vec1, vec2))"
   ]
  },
  {
   "source": [
    "# Building clue word distances from spacy words"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Getting all spacy words and cleaning them (remove duplicates, keep alpha-numeric word)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "295030"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "all_spacy_words = []\n",
    "for num_vec_tup in list(nlp.vocab.vectors.items()):\n",
    "    all_spacy_words.append(nlp.vocab.strings[num_vec_tup[0]].lower())\n",
    "\n",
    "# Keep unique only\n",
    "spacy_words_unique = list(set(all_spacy_words))\n",
    "\n",
    "# Only alpha-numeric words allowed\n",
    "spacy_words_unique_clean = [word for word in spacy_words_unique\n",
    "                            if re.match(r\"^[a-zA-Z0-9]+(-[a-zA-Z0-9]+)*$\",word)]\n",
    "len(spacy_words_unique_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['smeagol',\n",
       " 'rakia',\n",
       " 'soha',\n",
       " 'pleated',\n",
       " 'asslickers',\n",
       " 'three-station',\n",
       " 'poise',\n",
       " 'nausia',\n",
       " 'milley',\n",
       " 'facultad']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "spacy_words_unique_clean[:10]"
   ]
  },
  {
   "source": [
    "### Read all boardwords from ``wordlist.txt``"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "parent = os.path.dirname(path) \n",
    "board_words_path = os.path.join(parent, 'wordlist.txt')\n",
    "\n",
    "boardwords = []\n",
    "with open(board_words_path) as word_file:\n",
    "        boardwords += word_file.read().splitlines() "
   ]
  },
  {
   "source": [
    "### Use ``build_matrix`` with the word lists (clues & boardwords)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1min 40s, sys: 154 ms, total: 1min 40s\nWall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Takes a few minutes\n",
    "clues_matrix = build_matrix(spacy_words_unique_clean)\n",
    "boardwords_matrix = build_matrix(boardwords)"
   ]
  },
  {
   "source": [
    "### Create ``clue_word_distances``:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clue_word_distances = {}\n",
    "\n",
    "clue_word_distances['boardwords'] = {}\n",
    "for i in range(len(boardwords)):\n",
    "    clue_word_distances['boardwords'][boardwords[i]] = i\n",
    "\n",
    "clue_word_distances['clue_words'] = {}\n",
    "for i in range(len(spacy_words_unique_clean)):\n",
    "    clue_word_distances['clue_words'][spacy_words_unique_clean[i]] = i\n",
    "\n",
    "clue_word_distances['distances'] = cosine_distances(boardwords_matrix, clues_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('clue_word_distances.pkl', 'wb') as handle:\n",
    "    pickle.dump(clue_word_distances, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ]
}